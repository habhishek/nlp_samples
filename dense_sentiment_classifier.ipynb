{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dense_sentiment_classifier.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNGW6n0s44q+zylFH7mOezN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/habhishek/nlp_samples/blob/main/dense_sentiment_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqRa9CPYcQ-l"
      },
      "source": [
        "### Load the dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYuvBk8Ub6lu"
      },
      "source": [
        "\n",
        "import tensorflow\n",
        "from tensorflow.keras.datasets import imdb # new! \n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences #new!\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.layers import Embedding # new!\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint # new! \n",
        "import os # new! \n",
        "from sklearn.metrics import roc_auc_score, roc_curve # new!\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9I9sxHycbNF"
      },
      "source": [
        "#### Set Hyperparamters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbRy3BJycX9f"
      },
      "source": [
        "output_dir = 'model_output/dense'\n",
        "\n",
        "# training\n",
        "epochs = 4\n",
        "batch_size = 128\n",
        "\n",
        "# vector-space embedding\n",
        "n_dim = 64\n",
        "n_unique_words = 5000 # as per Maas et al. (2011)\n",
        "n_words_to_skip = 50 # assume - the 50 most frequently occuring words will be\n",
        "                     # stopwords\n",
        "max_review_length = 100\n",
        "pad_type = trunc_type = 'pre'\n",
        "\n",
        "# neural network architecture\n",
        "n_dense = 64\n",
        "dropout = 0.5"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9O2bqc9dl7z"
      },
      "source": [
        "#### Load Data\n",
        "\n",
        "\n",
        "For a given data set:\n",
        "\n",
        "* The TensorFlow Keras module's text utilities [here](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text) quickly preprocess natural language and convert it into an index\n",
        "\n",
        "* The Tokenizer class covered therein may do everything you need in a single line of code:\n",
        "** tokenize into words or characters\n",
        "** num_words: maximum unique tokens\n",
        "** filter out punctuation\n",
        "** lower case\n",
        "** convert words to an integer index\n",
        "\n",
        "* Other natural language preprocessing steps you may want to consider for your particular dataset and application are covered in the Natural Language Preprocessing notebook, including:\n",
        "** removing stop words\n",
        "** either stemming or lemmatization\n",
        "** colocating n-grams, such as bigrams and trigrams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Un1rPaX6dSwf",
        "outputId": "17d7bee3-d3b8-420b-d15d-35dd54e5c160"
      },
      "source": [
        "(x_train, y_train), (x_valid, y_valid) = imdb.load_data(num_words=n_unique_words,\n",
        "                                                        skip_top=n_words_to_skip)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBvboeEOfJyO",
        "outputId": "1afe3c18-50a1-4340-c385-2735862d1953"
      },
      "source": [
        "x_train[0:6] # 0 reserverd for padding; 1 would be starting character; since we\n",
        "# skip the 50 most common words, they are converted into unknown tokens represented by 2\n",
        "# first actual word is represented by 3 - most frequently occuring"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([list([2, 2, 2, 2, 2, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 2, 173, 2, 256, 2, 2, 100, 2, 838, 112, 50, 670, 2, 2, 2, 480, 284, 2, 150, 2, 172, 112, 167, 2, 336, 385, 2, 2, 172, 4536, 1111, 2, 546, 2, 2, 447, 2, 192, 50, 2, 2, 147, 2025, 2, 2, 2, 2, 1920, 4613, 469, 2, 2, 71, 87, 2, 2, 2, 530, 2, 76, 2, 2, 1247, 2, 2, 2, 515, 2, 2, 2, 626, 2, 2, 2, 62, 386, 2, 2, 316, 2, 106, 2, 2, 2223, 2, 2, 480, 66, 3785, 2, 2, 130, 2, 2, 2, 619, 2, 2, 124, 51, 2, 135, 2, 2, 1415, 2, 2, 2, 2, 215, 2, 77, 52, 2, 2, 407, 2, 82, 2, 2, 2, 107, 117, 2, 2, 256, 2, 2, 2, 3766, 2, 723, 2, 71, 2, 530, 476, 2, 400, 317, 2, 2, 2, 2, 1029, 2, 104, 88, 2, 381, 2, 297, 98, 2, 2071, 56, 2, 141, 2, 194, 2, 2, 2, 226, 2, 2, 134, 476, 2, 480, 2, 144, 2, 2, 2, 51, 2, 2, 224, 92, 2, 104, 2, 226, 65, 2, 2, 1334, 88, 2, 2, 283, 2, 2, 4472, 113, 103, 2, 2, 2, 2, 2, 178, 2]),\n",
              "       list([2, 194, 1153, 194, 2, 78, 228, 2, 2, 1463, 4369, 2, 134, 2, 2, 715, 2, 118, 1634, 2, 394, 2, 2, 119, 954, 189, 102, 2, 207, 110, 3103, 2, 2, 69, 188, 2, 2, 2, 2, 2, 249, 126, 93, 2, 114, 2, 2300, 1523, 2, 647, 2, 116, 2, 2, 2, 2, 229, 2, 340, 1322, 2, 118, 2, 2, 130, 4901, 2, 2, 1002, 2, 89, 2, 952, 2, 2, 2, 455, 2, 2, 2, 2, 1543, 1905, 398, 2, 1649, 2, 2, 2, 163, 2, 3215, 2, 2, 1153, 2, 194, 775, 2, 2, 2, 349, 2637, 148, 605, 2, 2, 2, 123, 125, 68, 2, 2, 2, 349, 165, 4362, 98, 2, 2, 228, 2, 2, 2, 1157, 2, 299, 120, 2, 120, 174, 2, 220, 175, 136, 50, 2, 4373, 228, 2, 2, 2, 656, 245, 2350, 2, 2, 2, 131, 152, 491, 2, 2, 2, 2, 1212, 2, 2, 2, 371, 78, 2, 625, 64, 1382, 2, 2, 168, 145, 2, 2, 1690, 2, 2, 2, 1355, 2, 2, 2, 52, 154, 462, 2, 89, 78, 285, 2, 145, 95]),\n",
              "       list([2, 2, 2, 2, 2, 2, 2, 2, 249, 108, 2, 2, 2, 54, 61, 369, 2, 71, 149, 2, 2, 112, 2, 2401, 311, 2, 2, 3711, 2, 75, 2, 1829, 296, 2, 86, 320, 2, 534, 2, 263, 4821, 1301, 2, 1873, 2, 89, 78, 2, 66, 2, 2, 360, 2, 2, 58, 316, 334, 2, 2, 1716, 2, 645, 662, 2, 257, 85, 1200, 2, 1228, 2578, 83, 68, 3912, 2, 2, 165, 1539, 278, 2, 69, 2, 780, 2, 106, 2, 2, 1338, 2, 2, 2, 2, 215, 2, 610, 2, 2, 87, 326, 2, 2300, 2, 2, 2, 2, 272, 2, 57, 2, 2, 2, 2, 2, 2, 2307, 51, 2, 170, 2, 595, 116, 595, 1352, 2, 191, 79, 638, 89, 2, 2, 2, 2, 106, 607, 624, 2, 534, 2, 227, 2, 129, 113]),\n",
              "       list([2, 2, 2, 2, 2, 2804, 2, 2040, 432, 111, 153, 103, 2, 1494, 2, 70, 131, 67, 2, 61, 2, 744, 2, 3715, 761, 61, 2, 452, 2, 2, 985, 2, 2, 59, 166, 2, 105, 216, 1239, 2, 1797, 2, 2, 2, 2, 744, 2413, 2, 2, 2, 687, 2, 2, 2, 2, 2, 3693, 2, 2, 2, 121, 59, 456, 2, 2, 2, 265, 2, 575, 111, 153, 159, 59, 2, 1447, 2, 2, 586, 482, 2, 2, 96, 59, 716, 2, 2, 172, 65, 2, 579, 2, 2, 2, 1615, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 464, 2, 314, 2, 2, 2, 719, 605, 2, 2, 202, 2, 310, 2, 3772, 3501, 2, 2722, 58, 2, 2, 537, 2116, 180, 2, 2, 413, 173, 2, 263, 112, 2, 152, 377, 2, 537, 263, 846, 579, 178, 54, 75, 71, 476, 2, 413, 263, 2504, 182, 2, 2, 75, 2306, 922, 2, 279, 131, 2895, 2, 2867, 2, 2, 2, 921, 2, 192, 2, 1219, 3890, 2, 2, 217, 4122, 1710, 537, 2, 1236, 2, 736, 2, 2, 61, 403, 2, 2, 2, 61, 4494, 2, 2, 4494, 159, 90, 263, 2311, 4319, 309, 2, 178, 2, 82, 4319, 2, 65, 2, 2, 145, 143, 2, 2, 2, 537, 746, 537, 537, 2, 2, 2, 2, 594, 2, 2, 94, 2, 3987, 2, 2, 2, 2, 538, 2, 1795, 246, 2, 2, 2, 2, 635, 2, 2, 51, 408, 2, 94, 318, 1382, 2, 2, 2, 2683, 936, 2, 2, 2, 2, 2, 2, 2, 1885, 2, 1118, 2, 80, 126, 842, 2, 2, 2, 2, 4726, 2, 4494, 2, 1550, 3633, 159, 2, 341, 2, 2733, 2, 4185, 173, 2, 90, 2, 2, 2, 2, 2, 1784, 86, 1117, 2, 3261, 2, 2, 2, 2, 2, 2, 2841, 2, 2, 1010, 2, 793, 2, 2, 1386, 1830, 2, 2, 246, 50, 2, 2, 2750, 1944, 746, 90, 2, 2, 2, 124, 2, 882, 2, 882, 496, 2, 2, 2213, 537, 121, 127, 1219, 130, 2, 2, 494, 2, 124, 2, 882, 496, 2, 341, 2, 2, 846, 2, 2, 2, 2, 1906, 2, 97, 2, 236, 2, 1311, 2, 2, 2, 2, 2, 2, 2, 91, 2, 3987, 70, 2, 882, 2, 579, 2, 2, 2, 2, 2, 537, 2, 2, 2, 2, 65, 2, 537, 75, 2, 1775, 3353, 2, 1846, 2, 2, 2, 154, 2, 2, 518, 53, 2, 2, 2, 3211, 882, 2, 399, 2, 75, 257, 3807, 2, 2, 2, 2, 456, 2, 65, 2, 2, 205, 113, 2, 2, 2, 2, 2, 2, 2, 242, 2, 91, 1202, 2, 2, 2070, 307, 2, 2, 2, 126, 93, 2, 2, 2, 188, 1076, 3222, 2, 2, 2, 2, 2348, 537, 2, 53, 537, 2, 82, 2, 2, 2, 2, 2, 280, 2, 219, 2, 2, 431, 758, 859, 2, 953, 1052, 2, 2, 2, 2, 94, 2, 2, 238, 60, 2, 2, 2, 804, 2, 2, 2, 2, 132, 2, 67, 2, 2, 2, 2, 283, 2, 2, 2, 2, 2, 242, 955, 2, 2, 279, 2, 2, 2, 1685, 195, 2, 238, 60, 796, 2, 2, 671, 2, 2804, 2, 2, 559, 154, 888, 2, 726, 50, 2, 2, 2, 2, 566, 2, 579, 2, 64, 2574]),\n",
              "       list([2, 249, 1323, 2, 61, 113, 2, 2, 2, 1637, 2, 2, 56, 2, 2401, 2, 457, 88, 2, 2626, 1400, 2, 3171, 2, 70, 79, 2, 706, 919, 2, 2, 355, 340, 355, 1696, 96, 143, 2, 2, 2, 289, 2, 61, 369, 71, 2359, 2, 2, 2, 131, 2073, 249, 114, 249, 229, 249, 2, 2, 2, 126, 110, 2, 473, 2, 569, 61, 419, 56, 429, 2, 1513, 2, 2, 534, 95, 474, 570, 2, 2, 124, 138, 88, 2, 421, 1543, 52, 725, 2, 61, 419, 2, 2, 1571, 2, 1543, 2, 2, 2, 2, 2, 296, 2, 3524, 2, 2, 421, 128, 74, 233, 334, 207, 126, 224, 2, 562, 298, 2167, 1272, 2, 2601, 2, 516, 988, 2, 2, 79, 120, 2, 595, 2, 784, 2, 3171, 2, 165, 170, 143, 2, 2, 2, 2, 2, 226, 251, 2, 61, 113]),\n",
              "       list([2, 778, 128, 74, 2, 630, 163, 2, 2, 1766, 2, 1051, 2, 2, 85, 156, 2, 2, 148, 139, 121, 664, 665, 2, 2, 1361, 173, 2, 749, 2, 2, 3804, 2, 2, 226, 65, 2, 2, 127, 2, 2, 2, 2])],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNQHwM5QfSAg",
        "outputId": "ea4eeed0-f097-464d-c645-a6892f8ed6b8"
      },
      "source": [
        "for x in x_train[0:6]:\n",
        "  print(len(x))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "218\n",
            "189\n",
            "141\n",
            "550\n",
            "147\n",
            "43\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lq4irVp2gMYd",
        "outputId": "c10c4201-2165-4a9e-8ed1-e794c63474c5"
      },
      "source": [
        "y_train[0:6]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 1, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5VZFRffgQZm",
        "outputId": "e7c15cf4-2c92-47d2-8e38-d6c703ab83a0"
      },
      "source": [
        "print(len(x_train), len(x_valid))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjZslo_sgfXW"
      },
      "source": [
        "#### Restoring words from index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFD0T5C6gdA1"
      },
      "source": [
        "word_index = tensorflow.keras.datasets.imdb.get_word_index()\n",
        "word_index = {k:(v+3) for k,v in word_index.items()}\n",
        "word_index[\"PAD\"] = 0\n",
        "word_index[\"START\"] = 1\n",
        "word_index[\"UNK\"] = 2"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKf3ql6Lg78w"
      },
      "source": [
        "word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9cdRGb_hBtr"
      },
      "source": [
        "index_word = {v:k for k,v in word_index.items()}"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnJzjswFhSAH"
      },
      "source": [
        "x_train[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "MtkU9uMJhVD7",
        "outputId": "212fd748-e781-4956-a3a0-b09c11a2c177"
      },
      "source": [
        "' '.join(index_word[id] for id in x_train[0])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"UNK UNK UNK UNK UNK brilliant casting location scenery story direction everyone's really suited UNK part UNK played UNK UNK could UNK imagine being there robert UNK UNK UNK amazing actor UNK now UNK same being director UNK father came UNK UNK same scottish island UNK myself UNK UNK loved UNK fact there UNK UNK real connection UNK UNK UNK UNK witty remarks throughout UNK UNK were great UNK UNK UNK brilliant UNK much UNK UNK bought UNK UNK UNK soon UNK UNK UNK released UNK UNK UNK would recommend UNK UNK everyone UNK watch UNK UNK fly UNK UNK amazing really cried UNK UNK end UNK UNK UNK sad UNK UNK know what UNK say UNK UNK cry UNK UNK UNK UNK must UNK been good UNK UNK definitely UNK also UNK UNK UNK two little UNK UNK played UNK UNK UNK norman UNK paul UNK were UNK brilliant children UNK often left UNK UNK UNK UNK list UNK think because UNK stars UNK play them UNK grown up UNK such UNK big UNK UNK UNK whole UNK UNK these children UNK amazing UNK should UNK UNK UNK what UNK UNK done don't UNK think UNK whole story UNK UNK lovely because UNK UNK true UNK UNK someone's life after UNK UNK UNK UNK UNK us UNK\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4YXZitOhk8m",
        "outputId": "a20e8aaf-ef8e-4332-827c-9b22d0088324"
      },
      "source": [
        "# to compare data which has all the frequently occuring words\n",
        "(all_x_train, _), (all_x_valid, _) = imdb.load_data()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "v2zxzIGTiQBf",
        "outputId": "e53fe5bd-044b-4d71-b30a-600fed1660de"
      },
      "source": [
        "' '.join(index_word[id] for id in all_x_train[0])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"START this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert redford's is an amazing actor and now the same being director norman's father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for retail and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also congratulations to the two little boy's that played the part's of norman and paul they were just brilliant children are often left out of the praising list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-DkR31-iiU3"
      },
      "source": [
        "#### Preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0EEOXVxiZ6g"
      },
      "source": [
        "x_train = pad_sequences(x_train, maxlen=max_review_length,\n",
        "                        padding=pad_type, truncating=trunc_type, value=0)\n",
        "x_valid = pad_sequences(x_valid, maxlen=max_review_length,\n",
        "                        padding=pad_type, truncating=trunc_type, value=0)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEYPXR7Uy9jO",
        "outputId": "c914b921-0c3e-4411-ee08-10a623e0a53c"
      },
      "source": [
        "len(x_train)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ihpcd_1kw1l"
      },
      "source": [
        "#### Design neural network architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLKPfDS3koVZ"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "# first hidden layer:\n",
        "model.add(Embedding(n_unique_words, n_dim, input_length=max_review_length))\n",
        "model.add(Flatten())\n",
        "\n",
        "# second hidden layer:\n",
        "model.add(Dense(n_dense, activation='relu'))\n",
        "model.add(Dropout(dropout))\n",
        "\n",
        "# model.add(Dense(n_dense, activation='relu'))\n",
        "# model.add(Dropout(dropout))\n",
        "\n",
        "# output_layer\n",
        "model.add(Dense(1, activation='sigmoid')) # mathematically equivalent to softmax\n",
        "                                           # with 2 classes"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUdLL6nEl390",
        "outputId": "c83b5991-f8b2-4d6d-ac72-5ee8d1b839c5"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 100, 64)           320000    \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 6400)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                409664    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 729,729\n",
            "Trainable params: 729,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNPpErOnl9oh",
        "outputId": "c8f2eb18-5b5c-49a2-afae-1c31d2a10202"
      },
      "source": [
        "# embedding layer dimensions and parameters:\n",
        "n_dim, n_unique_words, n_dim*n_unique_words"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(64, 5000, 320000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFXWiG0BmYep",
        "outputId": "897a848e-b725-4f33-9b24-eee590c359eb"
      },
      "source": [
        "# flatten:\n",
        "max_review_length, n_dim, n_dim*max_review_length"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 64, 6400)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQEmv53jm7-8",
        "outputId": "65615649-74e3-4526-8d8d-61fd6ff6b65f"
      },
      "source": [
        "# ...dense:\n",
        "n_dense, n_dim*max_review_length*n_dense + n_dense # weights + biases"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(64, 409664)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-S31u6VRxi4Z"
      },
      "source": [
        "#### Configure Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fu-izkumncHj"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['accuracy'])"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DO4OHcWqxzSc"
      },
      "source": [
        "modelcheckpoint = ModelCheckpoint(filepath=output_dir+\"/weights.{epoch:02d}.hdf5\")\n",
        "\n",
        "if not os.path.exists(output_dir):\n",
        "  os.makedirs(output_dir)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_T1up-TyTGs"
      },
      "source": [
        "#### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfNCZyp_yOpO",
        "outputId": "3f5b21e6-a973-4b71-8046-58d02108e549"
      },
      "source": [
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size, epochs=epochs, verbose=1,\n",
        "          validation_data=(x_valid, y_valid),\n",
        "          callbacks=[modelcheckpoint])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "196/196 [==============================] - 4s 17ms/step - loss: 0.5541 - accuracy: 0.6947 - val_loss: 0.3600 - val_accuracy: 0.8395\n",
            "Epoch 2/4\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 0.2866 - accuracy: 0.8845 - val_loss: 0.3473 - val_accuracy: 0.8470\n",
            "Epoch 3/4\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 0.1212 - accuracy: 0.9631 - val_loss: 0.4250 - val_accuracy: 0.8331\n",
            "Epoch 4/4\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 0.0294 - accuracy: 0.9950 - val_loss: 0.5296 - val_accuracy: 0.8275\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f30dc545f50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-OMniXGymLF"
      },
      "source": [
        "model.load_weights(output_dir+\"/weights.01.hdf5\")"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeT_f3qA0SOT",
        "outputId": "382c7de7-e20e-443d-be31-5a3c95c9ee1b"
      },
      "source": [
        "y_hat = model.predict_proba(x_valid)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:430: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
            "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kihqzgNb0XY4",
        "outputId": "31f3a35a-31b9-41e7-9c2b-d0e3a5ae924b"
      },
      "source": [
        "len(y_hat)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0T7cvMy0Y7L",
        "outputId": "18732a3d-67d2-4ac5-eb9a-61702756f6d0"
      },
      "source": [
        "y_hat[0], y_valid[0]"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.71795315], dtype=float32), 0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "8FfxbJ280hjP",
        "outputId": "09cca023-5f19-4fde-ea91-ad25300751db"
      },
      "source": [
        "plt.hist(y_hat)\n",
        "_ = plt.axvline(x=0.5, color='orange')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1I-l8Wgm02ZR"
      },
      "source": [
        "pct_auc = roc_auc_score(y_valid, y_hat)*100.0"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsPmstdL1GbI",
        "outputId": "d352b2ca-6354-4883-bb95-c645968f142a"
      },
      "source": [
        "pct_auc"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "92.404744"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhTf3jv81dSh",
        "outputId": "b22705ee-181f-4669-9ea7-f5bf07b1f413"
      },
      "source": [
        "y_hat[0][0]"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.71795315"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_SUeVle1K3E"
      },
      "source": [
        "float_y_hat = []\n",
        "for y in y_hat:\n",
        "  float_y_hat.append(y[0])"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpjersqM1i_a"
      },
      "source": [
        "ydf = pd.DataFrame(list(zip(float_y_hat, y_valid)), columns=['y_hat', 'y'])"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "IxExebeV1xgx",
        "outputId": "a1329e80-36a1-4715-c4a6-30057277d10b"
      },
      "source": [
        "ydf.head(20)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y_hat</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.717953</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.919630</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.771239</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.276946</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.975027</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.791645</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.893077</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.066053</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.875327</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.734749</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.747341</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.155156</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.030411</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.054969</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.952532</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.019328</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.947164</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.413496</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.015290</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.058925</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       y_hat  y\n",
              "0   0.717953  0\n",
              "1   0.919630  1\n",
              "2   0.771239  1\n",
              "3   0.276946  0\n",
              "4   0.975027  1\n",
              "5   0.791645  1\n",
              "6   0.893077  1\n",
              "7   0.066053  0\n",
              "8   0.875327  0\n",
              "9   0.734749  1\n",
              "10  0.747341  1\n",
              "11  0.155156  0\n",
              "12  0.030411  0\n",
              "13  0.054969  0\n",
              "14  0.952532  1\n",
              "15  0.019328  0\n",
              "16  0.947164  1\n",
              "17  0.413496  0\n",
              "18  0.015290  0\n",
              "19  0.058925  0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "FKqm8dGp1zKS",
        "outputId": "75049fca-7b26-4f12-9afe-6b63a4c48ed4"
      },
      "source": [
        "' '.join(index_word[id] for id in all_x_valid[0])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"START please give this one a miss br br kristy swanson and the rest of the cast rendered terrible performances the show is flat flat flat br br i don't know how michael madison could have allowed this one on his plate he almost seemed to know this wasn't going to work out and his performance was quite lacklustre so all you madison fans give this a miss\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "-S98cP292GHG",
        "outputId": "1c95d2c2-1b9a-484f-c08e-05f7329a67af"
      },
      "source": [
        "# try to filter the false positives\n",
        "\n",
        "ydf[(ydf.y == 0) & (ydf.y_hat > 0.9)].head(10)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y_hat</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>256</th>\n",
              "      <td>0.934687</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>386</th>\n",
              "      <td>0.907679</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>447</th>\n",
              "      <td>0.921434</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>680</th>\n",
              "      <td>0.914536</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>740</th>\n",
              "      <td>0.942515</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>781</th>\n",
              "      <td>0.921765</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>810</th>\n",
              "      <td>0.928647</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>921</th>\n",
              "      <td>0.927948</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>0.907894</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1059</th>\n",
              "      <td>0.941230</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         y_hat  y\n",
              "256   0.934687  0\n",
              "386   0.907679  0\n",
              "447   0.921434  0\n",
              "680   0.914536  0\n",
              "740   0.942515  0\n",
              "781   0.921765  0\n",
              "810   0.928647  0\n",
              "921   0.927948  0\n",
              "999   0.907894  0\n",
              "1059  0.941230  0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "487kmj0n2fqq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}